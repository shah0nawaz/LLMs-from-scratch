{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198628be-2a46-4212-b04d-ea00bc3a0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96364768-ae18-440c-9951-f3d685b851f7",
   "metadata": {},
   "source": [
    "# Simplified Self Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a79fa4-dc7c-44d8-824d-6aaeea9b59a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "[[0.43, 0.15, 0.89], # Your\n",
    "[0.55, 0.87, 0.66], # journey\n",
    "[0.57, 0.85, 0.64], # starts\n",
    "[0.22, 0.58, 0.33], # with\n",
    "[0.77, 0.25, 0.10], # one\n",
    "[0.05, 0.80, 0.55]] # step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38092df0-e269-4d76-a1d6-d58281d6b6c7",
   "metadata": {},
   "source": [
    "# Attention vecto for Single Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c656e891-1bad-4d7b-8c15-14aae507bdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "print(inputs.shape[0])\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query)\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5713984f-1a56-435a-b369-673941119731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_attn_scores(query, inputs):\n",
    "    attn_scores = torch.empty(inputs.shape[0])\n",
    "    for i, k_i in enumerate(inputs):\n",
    "        print(f'query: {query.shape} and key {k_i.shape}')\n",
    "        attn_scores[i] = torch.dot(k_i, query)\n",
    "        # normalization\n",
    "    # attn_scores = attn_scores / attn_scores.sum()\n",
    "    # attn_scores = softmax(attn_scores)\n",
    "    attn_scores = torch.softmax(attn_scores, dim=0)\n",
    "    return attn_scores\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22584ff7-19b1-4a83-b4d3-236e4215e027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: torch.Size([3]) and key torch.Size([3])\n",
      "query: torch.Size([3]) and key torch.Size([3])\n",
      "query: torch.Size([3]) and key torch.Size([3])\n",
      "query: torch.Size([3]) and key torch.Size([3])\n",
      "query: torch.Size([3]) and key torch.Size([3])\n",
      "query: torch.Size([3]) and key torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "attn_weights_v2 = calculate_attn_scores(query, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2fea9f7-c84f-4670-962b-3be667bc27ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = inputs[1]\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_v2[i]*x_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326f0b3e-60b6-4358-a9a3-603fbcf13e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5edf3a9-393e-4f0a-95c2-b10a69626b14",
   "metadata": {},
   "source": [
    "# For all Queries, Keys and Values \n",
    "\n",
    "# context_matrix = softmax(inputs*inputs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "459a3500-7f09-4b20-8f6c-53fbd37f21e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = torch.empty(inputs.shape[0], inputs.shape[0])\n",
    "for i, query in enumerate(inputs):\n",
    "    for j, key in enumerate(inputs):\n",
    "        attn_scores[i,j] = torch.dot(query, key)\n",
    "context_matrix = torch.softmax(attn_scores, dim=-1)\n",
    "print(context_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ce84ad1-0ed2-48a3-9edd-ff2a44198d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = inputs @ inputs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48cd9f28-0a1d-4d0b-9200-78a94973fb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "context_matrix = torch.softmax(attn_scores, dim=-1)\n",
    "print(context_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df80850a-cc7b-4f69-b1ef-4fd5508724fc",
   "metadata": {},
   "source": [
    "# Context_matrix * Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2d96cb1-71ad-4098-885a-2534623cfb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = context_matrix @ inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a57119e-cc31-4a4e-bfc9-c453c9714cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5814d0-c7e4-46db-a52f-b20900f945b5",
   "metadata": {},
   "source": [
    "# Self Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd23a053-1e52-4a4d-a04e-b3422e92483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d4ef06b-4df4-4cf0-918f-13dba26e9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ac8c2e5-1c23-4d18-9242-17c3250201ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = x_2 @ W_query\n",
    "key = x_2 @ W_key\n",
    "value = x_2 @ W_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea7939da-3f81-46e4-ac11-704e1979c815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551], grad_fn=<SqueezeBackward3>)\n"
     ]
    }
   ],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60a5fe6d-28bb-43e6-8eba-c3daa23a5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = inputs @ W_query\n",
    "key = inputs @ W_key\n",
    "value = inputs @ W_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e739a005-30b7-4c28-a9a8-5453eaa3ec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query shape: torch.Size([6, 2]), key shape: torch.Size([6, 2]), value: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f'query shape: {query.shape}, key shape: {key.shape}, value: {value.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f69ce046-e06e-4917-a8a8-da025c4cd571",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_score = query @ key.T\n",
    "d_k = key.shape[-1]\n",
    "atten_weights = torch.softmax(attention_score/ d_k **5, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "988e20c1-3491-4c32-a386-2def13bfe494",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vector = atten_weights @ value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fa527c-316d-4f97-b0fe-9c8be6fc42cf",
   "metadata": {},
   "source": [
    "# Self Attention Python Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48b33793-a2b5-4170-ab54-75ef882553cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_q = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "        self.W_k = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "        self.W_v = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "\n",
    "    def forward(self , x):\n",
    "        Q = x @ self.W_q\n",
    "        K = x @ self.W_k\n",
    "        V = x @ self.W_v\n",
    "        d_k = K.shape[-1]\n",
    "        attn_score = Q @ K.T\n",
    "        \n",
    "        attn_score_scaled = attn_score/d_k**0.5\n",
    "        attn_weights = torch.softmax(attn_score_scaled, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ V\n",
    "        return context_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3790ccc5-3dc1-44f3-bb21-9756e05545eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch.nn as nn\n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   =  nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self , x):\n",
    "        Q = self.W_query(x)\n",
    "        K = self.W_key(x)\n",
    "        V = self.W_value(x)\n",
    "        d_k = K.shape[-1]\n",
    "        attn_score = Q @ K.T\n",
    "        \n",
    "        attn_score_scaled = attn_score / d_k**0.5\n",
    "        attn_weights = torch.softmax(attn_score_scaled, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ V\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4253916b-0d0a-4d06-a45a-3fc27c4ebc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "selfattn = SelfAttention_v2(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67fcad8b-695f-4e3d-a003-2a1816b1c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = selfattn(inputs)\n",
    "# print(inputs)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cd6d8f-b537-4292-acd4-29d8b525ef94",
   "metadata": {},
   "source": [
    "# Mask Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7eab8ed-39b1-46c2-8639-826669a1adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch.nn as nn\n",
    "\n",
    "class SelfAttention_v3(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   =  nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self , x):\n",
    "        Q = self.W_query(x)\n",
    "        K = self.W_key(x)\n",
    "        V = self.W_value(x)\n",
    "        d_k = K.shape[-1]\n",
    "        attn_score = Q @ K.T\n",
    "        mask = torch.tril(torch.ones(x.shape[0], x.shape[0]))\n",
    "        \n",
    "        attn_score_scaled = attn_score / d_k**0.5\n",
    "        masked_attn_weights = torch.softmax(attn_score_scaled, dim=-1) * mask\n",
    "        masked_attn_weights = masked_attn_weights / masked_attn_weights.sum(dim=-1, keepdim=True)\n",
    "        print(masked_attn_weights)\n",
    "        context_vec = masked_attn_weights @ V\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da806cf4-59de-409d-a135-e492a9d1b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selfattn = SelfAttention_v3(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "475ed886-09da-4c59-bd14-0e47239dbdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5437, 0.4563, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3728, 0.3128, 0.3144, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2642, 0.2425, 0.2431, 0.2502, 0.0000, 0.0000],\n",
      "        [0.2146, 0.1890, 0.1896, 0.1969, 0.2099, 0.0000],\n",
      "        [0.1760, 0.1605, 0.1610, 0.1664, 0.1749, 0.1612]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[0.4566, 0.2729],\n",
      "        [0.5792, 0.3011],\n",
      "        [0.6249, 0.3102],\n",
      "        [0.5691, 0.2785],\n",
      "        [0.5543, 0.2520],\n",
      "        [0.5337, 0.2499]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = selfattn(inputs)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecec777f-e91a-4a90-84d5-e9f779c290a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch.nn as nn\n",
    "\n",
    "class SelfAttention_v4(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   =  nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self , x):\n",
    "        Q = self.W_query(x)\n",
    "        K = self.W_key(x)\n",
    "        V = self.W_value(x)\n",
    "        d_k = K.shape[-1]\n",
    "        \n",
    "        attn_score = Q @ K.T\n",
    "        mask = torch.triu(torch.ones(x.shape[0], x.shape[0]), diagonal=1)\n",
    "        attn_score_scaled = attn_score / d_k**0.5\n",
    "        masked_attn_weights = attn_score_scaled.masked_fill(mask.bool(), -torch.inf)\n",
    "\n",
    "        masked_attn_weights = torch.softmax(masked_attn_weights, dim=-1)\n",
    "        context_vec = masked_attn_weights @ V\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75cb68fe-bfcb-4887-9b18-3e42bc0d6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "selfattn = SelfAttention_v4(3,2)\n",
    "x = selfattn(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54d5c235-7ddb-4071-84c8-f2e97944c606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5684,  0.5063],\n",
      "        [-0.5388,  0.6447],\n",
      "        [-0.5242,  0.6954],\n",
      "        [-0.4578,  0.6471],\n",
      "        [-0.4006,  0.5921],\n",
      "        [-0.3997,  0.5971]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18eb736-d903-4862-802d-881d0b67a7b4",
   "metadata": {},
   "source": [
    "# Implementing a compact causal attention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "06a8e4b1-f507-4c10-8c77-258378736406",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout ,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        \n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.register_buffer(\n",
    "        'mask',\n",
    "        torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        b, num_tokens, d_in = x.shape\n",
    "        Q = self.W_query(x)\n",
    "        K = self.W_key(x)\n",
    "        V = self.W_value(x)\n",
    "        attn_score = Q @ K.transpose(1,2)\n",
    "        attn_scores.masked_fill_(\n",
    "        self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / self.d_out**0.5, dim=-1)\n",
    "        \n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        context_vec = attn_weights @ V\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3f1d2a54-c3cc-4cbd-94bc-2c1b24f012a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = CausalAttention(3,2,6,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dd88e859-5981-4f4f-a813-1acfe0314222",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.stack((inputs, inputs, inputs), dim=0)\n",
    "x = ca(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "64cc09d1-1822-4fb8-a6d2-5b33ddbe3f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.1360, -0.1767],\n",
      "         [-1.5790, -0.3089],\n",
      "         [-0.9782, -0.1781],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [-0.6150, -0.1111],\n",
      "         [-0.7535, -0.1529]],\n",
      "\n",
      "        [[-1.1360, -0.1767],\n",
      "         [-1.5790, -0.3089],\n",
      "         [-0.9782, -0.1781],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [-0.6150, -0.1111],\n",
      "         [-0.7535, -0.1529]],\n",
      "\n",
      "        [[-1.1360, -0.1767],\n",
      "         [-1.5790, -0.3089],\n",
      "         [-0.9782, -0.1781],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [-0.6150, -0.1111],\n",
      "         [-0.7535, -0.1529]]], grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd214831-491d-4823-9149-9614fa2e8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length , \n",
    "                 dropout,num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = [CausalAttention(\n",
    "            d_in, d_out, \n",
    "            context_length, dropout)\n",
    "            for _ in  range(num_heads)]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for head in self.heads:\n",
    "            return torch.cat([head(x) for head in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2f148238-87b7-4ad7-915a-b48f4f835a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiheadattentionwarpper = MultiHeadAttentionWrapper(3,2,6,0.5,3)\n",
    "out = multiheadattentionwarpper(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "86d5faa1-5f8a-45a6-bb72-cd99c89c5543",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = nn.Linear(6,2)\n",
    "out = lp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "38733e2c-8a72-4713-87db-d1b26d7a8304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "67fe3a36-5210-4dce-86f3-dc677562870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, num_heads,dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert(d_out%num_heads==0), \\\n",
    "        'd_out must be divisible by num_heads'\n",
    "        \n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = self.d_out // self.num_heads\n",
    "        \n",
    "        self.W_Q = nn.Linear(self.d_in, self.d_out, qkv_bias)\n",
    "        self.W_K = nn.Linear(self.d_in, self.d_out, qkv_bias)\n",
    "        self.W_V = nn.Linear(self.d_in, self.d_out, qkv_bias)\n",
    "        \n",
    "        self.register_buffer(\n",
    "        'mask',\n",
    "        torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "        self.projection = nn.Linear(self.d_out, self.d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_out = x.shape\n",
    "        Q = self.W_Q(x)\n",
    "        K = self.W_K(x)\n",
    "        V = self.W_V(x)\n",
    "        \n",
    "        Q = Q.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        K = K.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        V = V.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        \n",
    "        Q = Q.transpose(1,2)\n",
    "        K = K.transpose(1,2)\n",
    "        V = V.transpose(1,2)\n",
    "        \n",
    "        attn_score = Q @ K.transpose(2,3)\n",
    "        \n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / K.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vec = (attn_weights @ V).transpose(1,2)\n",
    "        context_vec = context_vec.contiguous().view(\n",
    "        b, num_tokens, self.d_out)\n",
    "        out = self.projection(context_vec)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7e7274f2-e5a5-451a-a8d5-f5b24250d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(3,2*5, 6 , 5, 0.5)\n",
    "# mha.W_K(batch)\n",
    "# mha.W_K(batch).view(3,6,5,2)\n",
    "# (mha.W_Q(batch).view(3,6,5,2).transpose(1,2) @ mha.W_K(batch).view(3,6,5,2).transpose(1,2).transpose(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bfa883bd-4d11-4b68-bc99-cdede2f0b8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 6, 6])\n",
      "torch.Size([3, 6, 10])\n"
     ]
    }
   ],
   "source": [
    "out = mha(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4c481b6c-0ce8-4c62-a9a5-1dc14af47a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 10])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "91b136ab-0d46-48c9-9844-28cd5adb7deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 4])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
    "[0.8993, 0.0390, 0.9268, 0.7388],\n",
    "[0.7179, 0.7058, 0.9156, 0.4340]],\n",
    "[[0.0772, 0.3565, 0.1479, 0.5331],\n",
    "[0.4066, 0.2318, 0.4545, 0.9737],\n",
    "[0.4606, 0.5159, 0.4220, 0.5786]]]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "57bcce8d-6fb3-45b9-a454-3899c4e35d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.3208, 1.1631, 1.2879],\n",
       "          [1.1631, 2.2150, 1.8424],\n",
       "          [1.2879, 1.8424, 2.0402]],\n",
       "\n",
       "         [[0.4391, 0.7003, 0.5903],\n",
       "          [0.7003, 1.3737, 1.0620],\n",
       "          [0.5903, 1.0620, 0.9912]]]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ a.transpose(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a0c47-d41d-46cb-9a40-9d4728f235ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c70a83ab-ea6d-4250-a28f-98ab1b366796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First head:\n",
      " tensor([[1.3208, 1.1631, 1.2879],\n",
      "        [1.1631, 2.2150, 1.8424],\n",
      "        [1.2879, 1.8424, 2.0402]])\n",
      "\n",
      "Second head:\n",
      " tensor([[0.4391, 0.7003, 0.5903],\n",
      "        [0.7003, 1.3737, 1.0620],\n",
      "        [0.5903, 1.0620, 0.9912]])\n"
     ]
    }
   ],
   "source": [
    "first_head = a[0, 0, :, :]\n",
    "first_res = first_head @ first_head.T\n",
    "print(\"First head:\\n\", first_res)\n",
    "second_head = a[0, 1, :, :]\n",
    "second_res = second_head @ second_head.T\n",
    "print(\"\\nSecond head:\\n\", second_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2d0f6-4d3e-4328-89c9-335783d1c6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8e097-257f-44cd-a844-5c6bd72b409d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
